{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "closing-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-bhutan",
   "metadata": {},
   "source": [
    "## LRP on a simple Markov-chain NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ideal-customer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix from layer 0 to 1:\n",
      "[[0.8 0.3]\n",
      " [0.2 0.7]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define widths of input, hidden and output layers\n",
    "layer_widths = [2,2]\n",
    "num_layers = len(layer_widths)\n",
    "\n",
    "# one transition (weight) matrix is of shape (layer_width x layer_width). We need (num_layers - 1) of them\n",
    "np.random.seed(5)\n",
    "weights = []\n",
    "for i in range(len(layer_widths) - 1):\n",
    "    W = np.random.uniform(size=(layer_widths[i+1], layer_widths[i]))\n",
    "    W /= W.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    # manual overwrite:\n",
    "    W = np.array([[.8, .3],\n",
    "                  [.2, .7]])\n",
    "    weights.append(W)\n",
    "    \n",
    "    print(f\"Weight matrix from layer {i} to {i+1}:\")\n",
    "    print(W, '\\n')\n",
    "\n",
    "# every weight matrix is a stochastic transition matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "completed-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1., 0.]), array([0.8, 0.2])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets \"classify\" something\n",
    "x = np.array([2., 0.])\n",
    "x /= x.sum()\n",
    "assert(len(x) == layer_widths[0])\n",
    "activations = [x]\n",
    "\n",
    "for W in weights:\n",
    "    activations.append(W @ activations[-1])\n",
    "    print(activations[-1].sum())\n",
    "    \n",
    "activations\n",
    "\n",
    "# the activations sum to 1 in every layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "marine-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets 'explain' the input using LRP-0 rule. we offer the standard way of initializating output layer relevancies R, and others.\n",
    "\n",
    "def LRP(weights, activations, initialization_method=\"default\", verbose=False, return_coefficients=False):\n",
    "    num_layers = len(activations)\n",
    "    assert(len(weights) + 1 == len(activations))\n",
    "    \n",
    "    R = [None]*num_layers\n",
    "    if (initialization_method == \"default\"):\n",
    "        R[-1] = activations[-1] * (activations[-1] == activations[-1].max())\n",
    "    elif (initialization_method == \"j_star_eq_1\"):\n",
    "        R[-1] = 1. * (activations[-1] == activations[-1].max())\n",
    "    elif (initialization_method == \"output_activations\"):\n",
    "        R[-1] = activations[-1]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    print(f\"R initialized with method {initialization_method}:\", R)\n",
    "    \n",
    "    # store matrices of LRP coefficients\n",
    "    coefficients = []\n",
    "    \n",
    "    for l in range(num_layers-2, -1, -1):\n",
    "        if (verbose):\n",
    "            print(\"\\ncalculating relevance for layer\", l)\n",
    "            print(f\"relevance for layer {l+1} was \\n\", R[l+1])\n",
    "            print(\"weights \\n\", weights[l])\n",
    "            print(W.shape, h.shape, h[None, :].shape)\n",
    "\n",
    "        W = weights[l]     # weights from the current to the deeper layer\n",
    "        h = activations[l] # activations of the current layer\n",
    "        R_prev = R[l+1]    # Relevance score of the deeper layer\n",
    "        \n",
    "        # C (vector form, one entry per entry in R[l+1])\n",
    "        C = W * h[None, :]\n",
    "        C /= C.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        coefficients.insert(0, C)\n",
    "        \n",
    "        R[l] = C.T @ R_prev\n",
    "        \n",
    "    if return_coefficients==True:\n",
    "        return coefficients\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-bubble",
   "metadata": {},
   "source": [
    "### Lets run LRP with different R_T initializations - how do the rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expensive-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R initialized with method output_activations: [None, array([0.8, 0.2])]\n",
      "\n",
      "R:           [array([1., 0.]), array([0.8, 0.2])]\n",
      "activations: [array([1., 0.]), array([0.8, 0.2])]\n"
     ]
    }
   ],
   "source": [
    "R = LRP(weights, activations, initialization_method=\"output_activations\")\n",
    "\n",
    "print()\n",
    "print(\"R:          \", R)\n",
    "print(\"activations:\", activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "residential-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R initialized with method default: [None, array([0.8, 0. ])]\n",
      "\n",
      "R:    [array([0.8, 0. ]), array([0.8, 0. ])]\n"
     ]
    }
   ],
   "source": [
    "R_default = LRP(weights, activations, initialization_method=\"default\")\n",
    "\n",
    "print()\n",
    "print(\"R:   \", R_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "egyptian-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R initialized with method j_star_eq_1: [None, array([1., 0.])]\n",
      "\n",
      "R:           [array([1., 0.]), array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "R_j_star_eq_1 = LRP(weights, activations, initialization_method=\"j_star_eq_1\")\n",
    "\n",
    "print()\n",
    "print(\"R:          \", R_j_star_eq_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cognitive-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_j_star_eq_1:          [array([1., 0.]), array([1., 0.])]\n",
      "R_default, normalized:  [array([1., 0.]), array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(\"R_j_star_eq_1:         \", R_j_star_eq_1)\n",
    "print(\"R_default, normalized: \", [unscaled / unscaled.sum() for unscaled in R_default])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-center",
   "metadata": {},
   "source": [
    "## In a Markov Chain NN, are the LRP weightings, computed for one input, in general the right inverse weight matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "significant-repeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import h0_W_h1_C_R0\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "funded-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix from layer 0 to 1:\n",
      "[[0.85536345 0.62931404]\n",
      " [0.14463655 0.37068596]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define widths of input, hidden and output layers\n",
    "layer_widths = [2,2]\n",
    "num_layers = len(layer_widths)\n",
    "\n",
    "# one transition (weight) matrix is of shape (layer_width x layer_width). We need (num_layers - 1) of them\n",
    "np.random.seed(56)\n",
    "weights = []\n",
    "for i in range(len(layer_widths) - 1):\n",
    "    W = np.random.uniform(size=(layer_widths[i+1], layer_widths[i]))\n",
    "    W[0,0] += 3\n",
    "    W /= W.sum(axis=0, keepdims=True)\n",
    "    weights.append(W)\n",
    "    \n",
    "    print(f\"Weight matrix from layer {i} to {i+1}:\")\n",
    "    print(W, '\\n')\n",
    "\n",
    "# every weight matrix is a stochastic transition matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "played-universal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.66666667, 0.33333333]), array([0.78001365, 0.21998635])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets \"classify\" something\n",
    "x = np.array([2., 1.])\n",
    "x /= x.sum()\n",
    "assert(len(x) == layer_widths[0])\n",
    "activations = [x]\n",
    "\n",
    "for W in weights:\n",
    "    activations.append(W @ activations[-1])\n",
    "    print(activations[-1].sum())\n",
    "    \n",
    "activations\n",
    "\n",
    "# the activations sum to 1 in every layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caroline-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R initialized with method default: [None, array([0.78001365, 0.        ])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.73106708, 0.26893292],\n",
       "        [0.43831976, 0.56168024]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = LRP(weights, activations, return_coefficients=True) # note: init method doesn't matter, coefficients are the same.\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "important-society",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.63984481, -2.78396667],\n",
       "        [-0.63984481,  3.78396667]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_weights = [np.linalg.inv(W) for W in weights]\n",
    "inverse_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "perfect-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.33333333])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forw0 = np.array([1, 5]).astype(float)\n",
    "forw0 /= forw0.sum()\n",
    "forw0 = x\n",
    "\n",
    "forw1 = weights[0] @ forw0\n",
    "# forw2 = weights[1] @ forw1\n",
    "\n",
    "forw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "impossible-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.33333333])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lrp2 = forw2\n",
    "lrp1 = forw1 # coefficients[1].T @ lrp2\n",
    "lrp0 = coefficients[0].T @ lrp1\n",
    "lrp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "comprehensive-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.33333333])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inv2 = forw2\n",
    "inv1 = forw1 # inverse_weights[1] @ inv2\n",
    "inv0 = inverse_weights[0] @ inv1\n",
    "inv0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
